{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mask_r_cnn_practice.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMcWX+qNfomU+GhnpiPmzD6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonggiChae/practice/blob/master/mask_r_cnn_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uJNq7Ff2--W"
      },
      "source": [
        "import torchvision\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import torch.nn as nn\r\n",
        "from torchvision.ops.boxes import batched_nms, box_iou, clip_boxes_to_image, remove_small_boxes\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision.transforms as T\r\n",
        "import torch.nn.init as nt\r\n",
        "from torchvision.ops import roi_align\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "# trf = T.compose([T.resize(),T.ToTensor()])\r\n",
        "# input_img = trf(img).unsqueeze(0)\r\n",
        "\r\n",
        "image = torch.zeros((1, 3, 800, 800)).float() \r\n",
        "\r\n",
        "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]]) # dummy box \r\n",
        "labels = torch.LongTensor([6, 8]) \r\n",
        "\r\n",
        "fe_size = 50\r\n",
        "\r\n",
        "\r\n",
        "dummy_img = torch.zeros((1, 3, 800,800)).float()\r\n",
        "# print(dummy_img)\r\n",
        "#Out: torch.Size([1, 3, 800, 800])\r\n",
        "\r\n",
        "\r\n",
        "model = torchvision.models.vgg16(pretrained=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def feature_extractor(model, image,fe_size):\r\n",
        "    fe = list(model.features)\r\n",
        "    req_features = []\r\n",
        "    k = image.clone()\r\n",
        "    for i in fe:\r\n",
        "        k = i(k)\r\n",
        "        # print(k.size())\r\n",
        "        if k.size()[2] < fe_size:\r\n",
        "            break\r\n",
        "        req_features.append(i)\r\n",
        "    faster_rcnn_fe_extractor = nn.Sequential(*req_features)\r\n",
        "    out_featuremap = faster_rcnn_fe_extractor(image)\r\n",
        "    return out_featuremap\r\n",
        "\r\n",
        "out_map = feature_extractor(model, dummy_img,fe_size)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb1L6Syf_-4u"
      },
      "source": [
        "# #Anchor Generator\r\n",
        "anchor_size = [128, 256, 512]\r\n",
        "anchor_ratio = [0.5, 1, 2]\r\n",
        "anchors = len(anchor_size) * len(anchor_ratio) * out_map.size(2) * out_map.size(3)\r\n",
        "h_ratios = np.sqrt(anchor_ratio)\r\n",
        "w_ratios = 1 / h_ratios\r\n",
        "anchor_boxes = torch.zeros((len(anchor_ratio) * len(anchor_size) * 50 * 50, 4) )\r\n",
        "\r\n",
        "\r\n",
        "def ctr_point(ctr_x, ctr_y):\r\n",
        "    index = 0\r\n",
        "    for x in range(len(ctr_x)):\r\n",
        "        for  y in range(len(ctr_y)):\r\n",
        "            ctr[index, 0] = ctr_x[x] - 8\r\n",
        "            ctr[index, 1] = ctr_y[y] - 8\r\n",
        "            index += 1\r\n",
        "    return ctr\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def anchor_boxes_each_point(anchor_boxes, ctr_x, ctr_y, anchor_size, anchor_ratio):\r\n",
        "   index = 0\r\n",
        "   for c in ctr:\r\n",
        "        ctr_y, ctr_x = c\r\n",
        "        # print(c)\r\n",
        "        for i in range(len(anchor_size)):\r\n",
        "            for j in range(len(anchor_ratio)):\r\n",
        "                h_ratios = np.sqrt(anchor_ratio[j])\r\n",
        "                w_ratios = 1 / h_ratios\r\n",
        "                h = anchor_size[i] * h_ratios\r\n",
        "                w = anchor_size[i] * w_ratios\r\n",
        "                anchor_boxes[index, 0] =  ctr_x - w / 2\r\n",
        "                anchor_boxes[index, 1] =  ctr_y - h / 2\r\n",
        "                anchor_boxes[index, 2] =  ctr_x + w / 2\r\n",
        "                anchor_boxes[index, 3] =  ctr_y + h / 2\r\n",
        "                index += 1\r\n",
        "            return anchor_boxes\r\n",
        "\r\n",
        "ctr_x = np.arange(16, (out_map.size(2)+1) * 16, 16)\r\n",
        "ctr_y = np.arange(16, (out_map.size(2)+1) * 16, 16)\r\n",
        "\r\n",
        "ctr = np.zeros((2500, 2))\r\n",
        "\r\n",
        "\r\n",
        "ctr_point(ctr_x, ctr_y)\r\n",
        "anchor_boxes_each_point(anchor_boxes, ctr_x, ctr_y, anchor_size, anchor_ratio)\r\n",
        "\r\n",
        "\r\n",
        "print(anchor_boxes.shape)\r\n",
        "print(bbox.shape)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0heu6OY_-0N"
      },
      "source": [
        "#iou\r\n",
        "pos_iou_threshold = 0.7\r\n",
        "neg_iou_threshold = 0.3\r\n",
        "\r\n",
        "\r\n",
        "ious = box_iou(anchor_boxes, bbox)\r\n",
        "\r\n",
        "\r\n",
        "gt_argmax_ious = ious.argmax(axis=0)\r\n",
        "# print(gt_argmax_ious)\r\n",
        "\r\n",
        "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]\r\n",
        "# print(gt_max_ious)\r\n",
        "\r\n",
        "gt_argmax_ious = np.where(ious == gt_max_ious)[0]\r\n",
        "# print(gt_argmax_ious)\r\n",
        "# print(np.arange(ious.shape[1]))\r\n",
        "\r\n",
        "\r\n",
        "# label = np.empty(22500, )\r\n",
        "# label.fill(-1)\r\n",
        "# label[gt_argmax_ious] = 1\r\n",
        "# print(gt_max_ious)\r\n",
        "# print(pos_iou_threshold)\r\n",
        "# print(label.shape)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# for index,i in enumerate(label):\r\n",
        "#     if gt_max_ious[index] >= pos_iou_threshold:\r\n",
        "#         label[index] = 1\r\n",
        "    \r\n",
        "# # label = np.where(gt_max_ious >= pos_iou_threshold)\r\n",
        "# # label[gt_max_ious < neg_iou_threshold] = 0\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foGcihbHW1Nw"
      },
      "source": [
        "#Determine vaild anchor, positve = 1, negative = 0 , (0.7 > i don't need > 0.3)\r\n",
        "pos_ratio = 0.5\r\n",
        "randomly_sample = 256\r\n",
        "pos = randomly_sample * pos_ratio \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fy4azeeZU0J"
      },
      "source": [
        "#bbox regression \r\n",
        "#predicting bounding box\r\n",
        "# t_{x} = (x - x_{a})/w_{a}\r\n",
        "# t_{y} = (y - y_{a})/h_{a}\r\n",
        "# t_{w} = log(w/ w_a)\r\n",
        "# t_{h} = log(h/ h_a)\r\n",
        "#groung truth box associate with a positive anchor\r\n",
        "# t_{x*} = (x* - x_{a})/w_{a}\r\n",
        "# t_{y*} = (y* - y_{a})/h_{a}\r\n",
        "# t_{w*} = log(w*/ w_a)\r\n",
        "# t_{h*} = log(h*/ h_a)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqpNtQccbOV2"
      },
      "source": [
        "#rpn_head\r\n",
        "#num_anchors = predicted box\r\n",
        "layer_weight = 0.1\r\n",
        "layer_bias = 0\r\n",
        "\r\n",
        "in_channels = 512\r\n",
        "num_anchors = len(anchor_size) * len(anchor_ratio)\r\n",
        "\r\n",
        "conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\r\n",
        "box_layer = nn.Conv2d(in_channels, num_anchors * 4, kernel_size=1, stride=1)\r\n",
        "score_layer = nn.Conv2d(in_channels, num_anchors, kernel_size=1, stride=1)\r\n",
        "conv.weight.data.normal_(layer_weight, std=0.01)\r\n",
        "box_layer.weight.data.normal_(layer_weight, std=0.01)\r\n",
        "score_layer.weight.data.normal_(layer_weight, std=0.01)\r\n",
        "conv.bias.data.zero_()\r\n",
        "box_layer.bias.data.zero_()\r\n",
        "score_layer.bias.data.zero_()\r\n",
        "\r\n",
        "\r\n",
        "x = conv(out_map)\r\n",
        "t = F.relu(conv(x))\r\n",
        "pred_anchor_locs = box_layer(t)\r\n",
        "pred_cls_scores = score_layer(t)\r\n",
        "print(pred_cls_scores.shape)\r\n",
        "\r\n",
        "\r\n",
        "pred_anchor_locs = pred_anchor_locs.permute(0, 2, 3, 1).contiguous().view(1, -1, 4)\r\n",
        "pred_cls_scores = pred_cls_scores.permute(0, 2, 3, 1).contiguous()\r\n",
        "objectness_score = pred_cls_scores.view(1, 50, 50, 9).contiguous().view(1, -1)\r\n",
        "pred_cls_scores  = pred_cls_scores.view(1, -1, 2)\r\n",
        "\r\n",
        "\r\n",
        "print(pred_anchor_locs.shape)\r\n",
        "print(pred_cls_scores.shape)\r\n",
        "print(objectness_score.shape)\r\n",
        "print(pred_cls_scores.shape)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HTIZmLX-Wc1"
      },
      "source": [
        "#rpn loss \r\n",
        "\r\n",
        "\r\n",
        "rpn_loc = pred_anchor_locs[0]\r\n",
        "rpn_score = pred_cls_scores[0]\r\n",
        "# gt_rpn_loc = \r\n",
        "# gt_rpn_score = \r\n",
        "\r\n",
        "def smooth_l1_loss(predicted_bbox, bbox_target):\r\n",
        "    n= torch.abs(predicted_bbox - bbox_target)\r\n",
        "    if n < 1:\r\n",
        "        loss = 0.5 * n ** 2\r\n",
        "    else:\r\n",
        "        loss = n - 0.5\r\n",
        "    return loss\r\n",
        "\r\n",
        "\r\n",
        "rpn_cls_loss = F.cross_entropy(rpn_score,anchor_labels)\r\n",
        "rpn_loc_loss = smooth_l1_loss(predicted_bbox, bbox_target).sum()\r\n",
        "\r\n",
        "#rpn loss function\r\n",
        "rpn_lambda = 10.\r\n",
        "N_reg = (gt_rpn_score >0).float().sum() # number of bounding box for positve anchors\r\n",
        "rpn_loc_loss = rpn_loc_loss / N_reg\r\n",
        "rpn_loss = rpn_cls_loss + (rpn_lambda * rpn_loc_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vMLp34Qnukm"
      },
      "source": [
        "#nms\r\n",
        "\r\n",
        "nms_thresh = 0.7\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1G4J7ypAjc7"
      },
      "source": [
        "#roi_align\r\n",
        "\r\n",
        "\r\n",
        "roi = roi_align(input, boxes, output_size = 7, spatial_scale)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Loss function\r\n",
        "\r\n",
        "reg_loss = 0\r\n",
        "\r\n",
        "def smooth_l1_loss(predicted_bbox, bbox_target):\r\n",
        "    n= torch.abs(predicted_bbox - bbox_target)\r\n",
        "    if n < 1:\r\n",
        "        loss = 0.5 * n ** 2\r\n",
        "    else:\r\n",
        "        loss = n - 0.5\r\n",
        "    return loss\r\n",
        "\r\n",
        "\r\n",
        "classification_loss = F.cross_entropy(class_score, labels)\r\n",
        "\r\n",
        "\r\n",
        "rpn_cls_loss = classification_loss\r\n",
        "rpn_loc_loss = smooth_l1_loss(predicted_bbox, bbox_target).sum()\r\n",
        "\r\n",
        "#rpn loss function\r\n",
        "rpn_lambda = 10.\r\n",
        "N_reg = (gt_rpn_score >0).float().sum() # number of bounding box for positve anchors\r\n",
        "rpn_loc_loss = rpn_loc_loss / N_reg\r\n",
        "rpn_loss = rpn_cls_loss + (rpn_lambda * rpn_loc_loss)\r\n",
        "\r\n",
        " \r\n",
        "#  x = #pixel \r\n",
        "# mask_binary_loss = sigmoid()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}