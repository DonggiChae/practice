# -*- coding: utf-8 -*-
"""vggnet_practice2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19YKeYFZ8wIfwBhOyXoeW-01T5lgZ0R2Q
"""

###https://tutorials.pytorch.kr/beginner/nn_tutorial.html

import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
import torchvision.datasets as dsets
import torchvision.transforms as transforms
from torch.utils.data import Dataset
from torch.utils.data import TensorDataset
from torch.utils.data import DataLoader
from google.colab import output


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

learning_rate = 0.01
training_epochs = 74
batch_size = 256
num_classes = 10



#????why???
transform = transforms.Compose(
    [transforms.Resize((224, 224)),
     transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])





classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

cifar10_train = dsets.CIFAR10(root = '/content/drive/MyDrive/dataset/input/', 
                                       train = True, 
                                       download=True,
                                       transform=transform
                                        )


train_loader = DataLoader(cifar10_train, batch_size=batch_size, shuffle=False)

cifar10_test = dsets.CIFAR10(root = '/content/drive/MyDrive/dataset/input/', 
                                       train = False, 
                                       download=True,
                                       transform = transform
                                        )


test_loader = DataLoader(cifar10_test, batch_size=batch_size, shuffle=False)


class vgg16_D(nn.Module):

    def __init__(self):
        super(vgg16_D, self).__init__()
        self.layers1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        
        self.layers2 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
       
        self.layers3 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
       
        self.layers4 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        
        self.layers5 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        
        self.fc = nn.Sequential(
            nn.Linear(512, 4096),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(),
            nn.Dropout(p=0.5),
            nn.Linear(4096, num_classes),
        )
        

    def forward(self, x):
        out = self.layers1(x)
        out = self.layers2(out)
        out = self.layers3(out)
        out = self.layers4(out)
        out = self.layers5(out)
        out = out.view(out.size(0), -1)   # Flatten them for FC
        out = self.fc(out)
        return out




model = vgg16_D().to(device)

criterion = nn.CrossEntropyLoss().to(device) #softmax
optimizer = optim.SGD(model.parameters(), lr=learning_rate)




total_batch = len(train_loader)
print('총 배치의 수 : {}'.format(total_batch))


#왜 data는 image , label 순서이지?왜??
for epoch in range(training_epochs):
    avg_cost = 0

    for index, data in enumerate(train_loader):
        image, label = data
        image = image.to(device)
        label = label.to(device)



        optimizer.zero_grad()
        hypothesis = model(image)
        cost = criterion(hypothesis, label)
        cost.backward()
        optimizer.step()

        avg_cost = cost / num_classes


    print(avg_cost)

"""# 새 섹션"""